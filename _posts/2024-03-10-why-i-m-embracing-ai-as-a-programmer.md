---
published: true
layout: post
title: "Why I'm Embracing AI as a Programmer"
author: vertis
minutes_read: 
feature_image:
  # url: https://imagedelivery.net/oX4qJVfXHjtomqEsf4Y2wg/e2ce0589-3ec8-451e-7a6a-563441853e00/w=800
  # preview_url: https://imagedelivery.net/oX4qJVfXHjtomqEsf4Y2wg/e2ce0589-3ec8-451e-7a6a-563441853e00/w=450
  url: https://imagedelivery.net/oX4qJVfXHjtomqEsf4Y2wg/b4553b59-aecd-46bf-d0bd-4b0d13c54700/w=800
  preview_url: https://imagedelivery.net/oX4qJVfXHjtomqEsf4Y2wg/b4553b59-aecd-46bf-d0bd-4b0d13c54700/w=450
caption: ""
meta_description: ""
tags:
  - 
---

I was on the wrong side, apparently, of the game [Ingress](https://www.ingress.com/) from [Niantic](https://nianticlabs.com/). While I don't play it anymore, I invested many hours when the game was new in 2013. The game revolved around two factions trying to capture nodes: the Enlightened (green) and the Resistance (blue). It had a simple storyline about exotic matter that some thought could be positive and others the dangerous, loosely reminiscent of "[Earth: Final Conflict](https://en.wikipedia.org/wiki/Earth:_Final_Conflict)".

I chose the Resistance at the time because protecting Earth? Right. Granted, it didn't matter all that much to the gameplay, and I certainly didn't put that much thought into the decision-making process.

But I find that I'm not the Resistance. I've been tracking the progress of [AI/ML](https://en.wikipedia.org/wiki/Machine_learning) since long before [GPT-3](https://en.wikipedia.org/wiki/GPT-3), but like everyone, I've become swept up in the new capabilities.

Increasingly, though, I keep coming across people who are not convinced or are worried about what the future will bring in a world where AI has replaced X job.

[Programmers](https://en.wikipedia.org/wiki/Programmer), it seems, are waking up to the reality that it won't just be other industries that are impacted, but that it will change the fundamental nature of programming. There are subsets of programmers who are in denial. There are subsets of programmers resisting the change.

Not me. I'm all in. I accept that there are risks around AI. I accept that there will be fundamental changes to my job and the jobs of millions of others. I just don't think it's something we can avoid.

A recent video from the [Singapore Parliament](https://www.parliament.gov.sg/) really highlights that the Powers That Beâ„¢ understand this.

<video controls>
  <source src="https://video.vertis.io/singapore_parliament_on_ai_learning_subsidy.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

To be clear, I don't think this will go far enough. It won't be enough to retrain. The member understands this, though, that even if Singapore were to try and block AI from impacting their citizens, it's an arms race. Some other country will embrace it, and it will just disadvantage the laggards.

For now, though, AI is giving me more advantages than many others. I've always been a generalist. The maxim "[Jack of all trades, master of none](https://en.wikipedia.org/wiki/Jack_of_all_trades,_master_of_none)" is often applied and is true in some senses.

In my two-decade career, I've moved through so many [languages](/garden/programming-languages-i-ve-known-and-loved), frameworks, and job roles that it becomes impossible to remember everything. If you don't do a task frequently, you might know it's possible, you might even know the correct result when you see it, but you're still going to have to look up how to do it.

All that changed substantially with the various tools that have become available over the last 2-3 years. Previously, it would be a cycle of doing a web search and then poring through various documentation and [Stack Overflow](https://stackoverflow.com/) posts looking for how to do that. An attention-diverting, momentum-destroying pause.

Not anymore. There are various calibers of tools out there, and they're not at 100% accuracy, but a large volume of the previous "pauses" are either much shorter or completely removed.

Even when the AI gets it wrong, sometimes that's just the prompt on the memory that's needed. I discover that it **is** in there somewhere after all.

We will get to the point where we're not programming at all, eventually. For now, it's moving to a much more streamlined development process, where developers can move through the tasks without getting blocked.

It rewards some of the behaviors that we should have been doing the whole time: building robust [test suites](https://en.wikipedia.org/wiki/Test_suite) that allow us to feed the errors straight back into the AI chat and move through the problems at a rapid pace.

My new workflow reminds me a lot of a game I used to play while [pair programming](https://en.wikipedia.org/wiki/Pair_programming). Each of the members would write a test, and then the other would try to implement it in the stupidest way possible. Testing for a "hello" response would result in a `return "hello"` method and a test for the next round that could not be so easily tricked. The back and forth with the AI feels very familiar.

Tools like [SweepAI](https://sweep.dev) try to take this one step further -- writing issues and receiving completed [PRs](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests). But they don't work, yet. It's an indication of what is to come, but at present, it's a slow and frustrating experience. When shorter completion tools go awry, it's a minor effort to bring them back into alignment or continue manually.

When [SweepAI](https://sweep.dev) goes off in the wrong direction, it's a much longer cycle of trying to get it back or abandoning the effort. When AI can do mundane upgrades, it'll be an invaluable tool, but not for now.